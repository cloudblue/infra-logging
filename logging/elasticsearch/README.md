# Elasticsearch

Here you will find the needed files to start an elastic stack composed by:

- Elasticsearch
- Kibana
- Curator


## Elasticsearch

Here you will find the needed helmfile to install elasticsearch.

We use the official helm charts, where we can install elastic node on kubernetes host node.

Our suggestions is to use 3 host nodes each one with an elastic node in order to have a fault tolerant and performance stack.

Also is created a kibana service to access elasticsearch and a curator cronjob to set up the retention policy.


## Security

In order to improve elasticsearch stack we set up the services following the security example found [here](https://github.com/elastic/helm-charts/tree/master/elasticsearch/examples/security)

For that reason there is a Makefile to generate all the certificate and secrets required.

Before execute the helmfile you need to generate the secrets for elastic and kibana. 
*Note: To run this make you need docker up and running on the host where you execute it*


```bash
make secrets-elastic

make secrets-kibana
```

## Install

Once done we install elasticsearch stack with:

```bash
helmfile -n infrastructure apply
```

## Fluent changes

To start to ingest logs on Elastic we need to turn on en the config file the option output_to_es.

```yaml
output_to_es: true
```

## Fields auto detected

From the logs generate by each pod we try to normalize some fields to allow easily the search.

The fields that you will see on elastic are:

General: 

* app: it came from kubernetes labels.
* host: kubernetes hostname where the pod is executed.
* namespace: kubernetes namespace.
* podname: kubernetes pod name.
* podname_orig: For bss-worker here we have the original pod name.
* containername: kubernetes container name.
* log_level: [INFO|DEBUG|ERROR|WARNING]
* is_exception: true if we found the string exception on the message
* stream: [stdout|stderror]
* message: the log generated by the pod.

In order to minimize disk space and CPU time we use a index_template
  
Specific for platform pods:

We use regular expressions to extract some information that seems relevant. 

Unfortunately the casuistic of each field is too long and it affects performance, so right now is deactivated.

To better understand this regular expression check the file [lua_scripts_extra.lua](../../filebase/config/fluentbit/lua_scripts_extra.lua).

For BSS:

* transaction_id: check function get_transaction_id()
* request_id: check the function get_request_id()
* th_id: check the function get_th_id()
* eventh_id: check the function get_eventh_id()
* subscription_id: check the function get_subscription_id()
  
For OSS:

* task_id: check the function get_task_id()
* account_id: check the function get_account_id()
* subscription_id: check the function get_subscription_id()
* uispan: check the function get_uispan()
* took_ms: check the function get_took_ms()

For pas-integration:

* task_id: check the function get_task_id()
* account_id: check the function get_account_id()
* subscription_id: check the function get_subscription_id()

For branding:

* uispan: check the function get_uispan()
* took_ms: check the function get_took_ms()

For rateddataexport:

* took_ms: check the function get_took_ms()

